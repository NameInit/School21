{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 09. Exercise 03\n",
    "# Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, BaggingClassifier, StackingClassifier\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create the same dataframe as in the previous exercise.\n",
    "2. Using `train_test_split` with parameters `test_size=0.2`, `random_state=21` get `X_train`, `y_train`, `X_test`, `y_test` and then get `X_train`, `y_train`, `X_valid`, `y_valid` from the previous `X_train`, `y_train`. Use the additional parameter `stratify`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numTrials</th>\n",
       "      <th>hour</th>\n",
       "      <th>uid_user_0</th>\n",
       "      <th>uid_user_1</th>\n",
       "      <th>uid_user_10</th>\n",
       "      <th>uid_user_11</th>\n",
       "      <th>uid_user_12</th>\n",
       "      <th>uid_user_13</th>\n",
       "      <th>uid_user_14</th>\n",
       "      <th>uid_user_15</th>\n",
       "      <th>...</th>\n",
       "      <th>labname_lab03</th>\n",
       "      <th>labname_lab03s</th>\n",
       "      <th>labname_lab05s</th>\n",
       "      <th>labname_laba04</th>\n",
       "      <th>labname_laba04s</th>\n",
       "      <th>labname_laba05</th>\n",
       "      <th>labname_laba06</th>\n",
       "      <th>labname_laba06s</th>\n",
       "      <th>labname_project1</th>\n",
       "      <th>dayofweek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1686 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      numTrials  hour  uid_user_0  uid_user_1  uid_user_10  uid_user_11  \\\n",
       "0             1     5         0.0         0.0          0.0          0.0   \n",
       "1             2     5         0.0         0.0          0.0          0.0   \n",
       "2             3     5         0.0         0.0          0.0          0.0   \n",
       "3             4     5         0.0         0.0          0.0          0.0   \n",
       "4             5     5         0.0         0.0          0.0          0.0   \n",
       "...         ...   ...         ...         ...          ...          ...   \n",
       "1681          9    20         0.0         0.0          0.0          0.0   \n",
       "1682          6    20         0.0         1.0          0.0          0.0   \n",
       "1683          7    20         0.0         1.0          0.0          0.0   \n",
       "1684          8    20         0.0         1.0          0.0          0.0   \n",
       "1685          9    20         0.0         1.0          0.0          0.0   \n",
       "\n",
       "      uid_user_12  uid_user_13  uid_user_14  uid_user_15  ...  labname_lab03  \\\n",
       "0             0.0          0.0          0.0          0.0  ...            0.0   \n",
       "1             0.0          0.0          0.0          0.0  ...            0.0   \n",
       "2             0.0          0.0          0.0          0.0  ...            0.0   \n",
       "3             0.0          0.0          0.0          0.0  ...            0.0   \n",
       "4             0.0          0.0          0.0          0.0  ...            0.0   \n",
       "...           ...          ...          ...          ...  ...            ...   \n",
       "1681          0.0          0.0          0.0          0.0  ...            0.0   \n",
       "1682          0.0          0.0          0.0          0.0  ...            0.0   \n",
       "1683          0.0          0.0          0.0          0.0  ...            0.0   \n",
       "1684          0.0          0.0          0.0          0.0  ...            0.0   \n",
       "1685          0.0          0.0          0.0          0.0  ...            0.0   \n",
       "\n",
       "      labname_lab03s  labname_lab05s  labname_laba04  labname_laba04s  \\\n",
       "0                0.0             0.0             0.0              0.0   \n",
       "1                0.0             0.0             0.0              0.0   \n",
       "2                0.0             0.0             0.0              0.0   \n",
       "3                0.0             0.0             0.0              0.0   \n",
       "4                0.0             0.0             0.0              0.0   \n",
       "...              ...             ...             ...              ...   \n",
       "1681             0.0             0.0             0.0              0.0   \n",
       "1682             0.0             0.0             0.0              0.0   \n",
       "1683             0.0             0.0             0.0              0.0   \n",
       "1684             0.0             0.0             0.0              0.0   \n",
       "1685             0.0             0.0             0.0              0.0   \n",
       "\n",
       "      labname_laba05  labname_laba06  labname_laba06s  labname_project1  \\\n",
       "0                0.0             0.0              0.0               1.0   \n",
       "1                0.0             0.0              0.0               1.0   \n",
       "2                0.0             0.0              0.0               1.0   \n",
       "3                0.0             0.0              0.0               1.0   \n",
       "4                0.0             0.0              0.0               1.0   \n",
       "...              ...             ...              ...               ...   \n",
       "1681             0.0             0.0              1.0               0.0   \n",
       "1682             0.0             0.0              1.0               0.0   \n",
       "1683             0.0             0.0              1.0               0.0   \n",
       "1684             0.0             0.0              1.0               0.0   \n",
       "1685             0.0             0.0              1.0               0.0   \n",
       "\n",
       "      dayofweek  \n",
       "0             4  \n",
       "1             4  \n",
       "2             4  \n",
       "3             4  \n",
       "4             4  \n",
       "...         ...  \n",
       "1681          3  \n",
       "1682          3  \n",
       "1683          3  \n",
       "1684          3  \n",
       "1685          3  \n",
       "\n",
       "[1686 rows x 44 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/day-of-week-not-scaled.csv')\n",
    "df['dayofweek']=pd.read_csv('../data/dayofweek.csv')['dayofweek']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(columns=['dayofweek'])\n",
    "y=df['dayofweek']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=21,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Individual classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train SVM, decision tree and random forest again with the best parameters that you got from the 01 exercise with `random_state=21` for all of them.\n",
    "2. Evaluate `accuracy`, `precision`, and `recall` for them on the validation set.\n",
    "3. The result of each cell of the section should look like this:\n",
    "\n",
    "```\n",
    "accuracy is 0.87778\n",
    "precision is 0.88162\n",
    "recall is 0.87778\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(model, X_test, y_test, show=False):\n",
    "\tpred_y = model.predict(X_test)\n",
    "\taccuracy = accuracy_score(pred_y, y_test)\n",
    "\tprecision = precision_score(pred_y, y_test, average='weighted')\n",
    "\trecall = recall_score(pred_y,y_test, average='weighted')\n",
    "\tif show:\n",
    "\t\tprint(f\"Accuracy: {accuracy:.5f}\")\n",
    "\t\tprint(f\"Precision: {precision:.5f}\")\n",
    "\t\tprint(f\"Recall: {recall:.5f}\")\n",
    "\treturn {'accuracy':accuracy,'precision':precision,'recall':recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.88757\n",
      "Precision: 0.88778\n",
      "Recall: 0.88757\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8875739644970414,\n",
       " 'precision': 0.8877813050077406,\n",
       " 'recall': 0.8875739644970414}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svm = SVC(C=10, class_weight='balanced', gamma='auto', kernel='rbf',random_state=21,probability=True)\n",
    "model_svm.fit(X_train, y_train)\n",
    "metrics(model_svm, X_test, y_test, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86686\n",
      "Precision: 0.86876\n",
      "Recall: 0.86686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8668639053254438,\n",
       " 'precision': 0.8687628004393987,\n",
       " 'recall': 0.8668639053254438}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tree = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=30, random_state=21)\n",
    "model_tree.fit(X_train, y_train)\n",
    "metrics(model_tree, X_test, y_test, show=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.92899\n",
      "Precision: 0.93328\n",
      "Recall: 0.92899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9289940828402367,\n",
       " 'precision': 0.9332817570155058,\n",
       " 'recall': 0.9289940828402367}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_forest = RandomForestClassifier(class_weight='balanced', criterion='gini', max_depth=40, n_estimators=50, random_state=21)\n",
    "model_forest.fit(X_train, y_train)\n",
    "metrics(model_forest, X_test, y_test, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Voting classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using `VotingClassifier` and the three models that you have just trained, calculate the `accuracy`, `precision`, and `recall` on the validation set.\n",
    "2. Play with the other parameteres.\n",
    "3. Calculate the `accuracy`, `precision` and `recall` on the test set for the model with the best weights in terms of accuracy (if there are several of them with equal values, choose the one with the higher precision)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9260355029585798,\n",
       " 'precision': 0.9287747789508352,\n",
       " 'recall': 0.9260355029585798}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_voting_hard = VotingClassifier(estimators=[('forest',model_forest),('svm', model_svm),('tree',model_tree)])\n",
    "model_voting_hard.fit(X_train, y_train)\n",
    "metrics(model_voting_hard, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9053254437869822,\n",
       " 'precision': 0.9080256487623768,\n",
       " 'recall': 0.9053254437869822}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_voting_soft = VotingClassifier(estimators=[('forest',model_forest),('svm', model_svm),('tree',model_tree)], voting='soft')\n",
    "model_voting_soft.fit(X_train, y_train)\n",
    "metrics(model_voting_soft, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [\n",
    "\t[1,1,1],\n",
    "\t[2,1,1],\n",
    "\t[1,2,1],\n",
    "\t[1,1,2]\n",
    "]\n",
    "\n",
    "best_param = {\n",
    "\t'model': None,\n",
    "\t'accuracy':0,\n",
    "\t'precision':0,\n",
    "\t'recall':0,\n",
    "\t'weights':[]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [2, 1, 1]\n",
      "Accuracy: 0.9289940828402367\n",
      "Precision: 0.9319120441073311\n",
      "Recall: 0.9289940828402367\n"
     ]
    }
   ],
   "source": [
    "for item_weights in weights:\n",
    "\tt_model_voting = VotingClassifier(estimators=[('forest',model_forest),('svm', model_svm),('tree',model_tree)], weights=item_weights)\n",
    "\tt_model_voting.fit(X_train, y_train)\n",
    "\tt_res=metrics(t_model_voting,X_test,y_test)\n",
    "\tif t_res['accuracy']>best_param['accuracy'] or (t_res['accuracy']==best_param['accuracy'] and t_res['precision']>best_param['precision']):\n",
    "\t\tbest_param['accuracy']=t_res['accuracy']\n",
    "\t\tbest_param['precision']=t_res['precision']\n",
    "\t\tbest_param['recall']=t_res['recall']\n",
    "\t\tbest_param['model']=t_model_voting\n",
    "\t\tbest_param['weights']=item_weights\n",
    "\n",
    "print(f\"Weights: {best_param['weights']}\")\n",
    "print(f\"Accuracy: {best_param['accuracy']}\")\n",
    "print(f\"Precision: {best_param['precision']}\")\n",
    "print(f\"Recall: {best_param['recall']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bagging classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using `BaggingClassifier` and `SVM` with the best parameters create an ensemble, try different values of the `n_estimators`, use `random_state=21`.\n",
    "2. Play with the other parameters.\n",
    "3. Calculate the `accuracy`, `precision`, and `recall` for the model with the best parameters (in terms of accuracy) on the test set (if there are several of them with equal values, choose the one with the higher precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_n_estimators = range(10,100,10)\n",
    "best_param_bagging = {\n",
    "\t'model': None,\n",
    "\t'accuracy':0,\n",
    "\t'precision':0,\n",
    "\t'recall':0,\n",
    "\t'n_estimators':0\n",
    "}\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_estimators in list_n_estimators:\n",
    "\tt_model_bagging = BaggingClassifier(estimator=model_svm, n_estimators=n_estimators, random_state=21)\n",
    "\tt_model_bagging.fit(X_train, y_train)\n",
    "\tt_res=metrics(t_model_bagging,X_test,y_test)\n",
    "\tif t_res['accuracy']>best_param_bagging['accuracy'] or (t_res['accuracy']==best_param_bagging['accuracy'] and t_res['precision']>best_param_bagging['precision']):\n",
    "\t\tbest_param_bagging['accuracy']=t_res['accuracy']\n",
    "\t\tbest_param_bagging['precision']=t_res['precision']\n",
    "\t\tbest_param_bagging['recall']=t_res['recall']\n",
    "\t\tbest_param_bagging['model']=t_model_bagging\n",
    "\t\tbest_param_bagging['n_estimators']=n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_estimators: 60\n",
      "Accuracy: 0.8964497041420119\n",
      "Precision: 0.8973594069747918\n",
      "Recall: 0.8964497041420119\n"
     ]
    }
   ],
   "source": [
    "print(f\"N_estimators: {best_param_bagging['n_estimators']}\")\n",
    "print(f\"Accuracy: {best_param_bagging['accuracy']}\")\n",
    "print(f\"Precision: {best_param_bagging['precision']}\")\n",
    "print(f\"Recall: {best_param_bagging['recall']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Stacking classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. To achieve reproducibility in this case you will have to create an object of cross-validation generator: `StratifiedKFold(n_splits=n, shuffle=True, random_state=21)`, where `n` you will try to optimize (the details are below).\n",
    "2. Using `StackingClassifier` and the three models that you have recently trained, calculate the `accuracy`, `precision` and `recall` on the validation set, try different values of `n_splits` `[2, 3, 4, 5, 6, 7]` in the cross-validation generator and parameter `passthrough` in the classifier itself,\n",
    "3. Calculate the `accuracy`, `precision`, and `recall` for the model with the best parameters (in terms of accuracy) on the test set (if there are several of them with equal values, choose the one with the higher precision). Use `final_estimator=LogisticRegression(solver='liblinear')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_n_splits = range(2,10,2)\n",
    "\n",
    "best_param_bagging = {\n",
    "\t'model': None,\n",
    "\t'accuracy':0,\n",
    "\t'precision':0,\n",
    "\t'recall':0,\n",
    "\t'n_splits':0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for n_splits in list_n_splits:\n",
    "\tfor passthrough in [True, False]:\n",
    "\t\tskf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=21)\n",
    "\n",
    "\t\tt_model_stacking = StackingClassifier(\n",
    "\t\t\testimators=[('svс', model_svm), ('forest', model_forest), ('tree', model_tree)],\n",
    "            passthrough=passthrough,\n",
    "            final_estimator=LogisticRegression(solver='liblinear')\n",
    "\t\t)\n",
    "\n",
    "\t\tfor train_index, val_index in skf.split(X_train, y_train):\n",
    "\t\t\tX_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "\t\t\ty_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "\t\t\tt_model_stacking.fit(X_train_fold, y_train_fold)\n",
    "\t\t\tt_res = metrics(t_model_stacking, X_val_fold, y_val_fold)\n",
    "\n",
    "\t\t\tif t_res['accuracy']>best_param_bagging['accuracy'] or (t_res['accuracy']==best_param_bagging['accuracy'] and t_res['precision']>best_param_bagging['precision']):\n",
    "\t\t\t\tbest_param_bagging['accuracy']=t_res['accuracy']\n",
    "\t\t\t\tbest_param_bagging['precision']=t_res['precision']\n",
    "\t\t\t\tbest_param_bagging['recall']=t_res['recall']\n",
    "\t\t\t\tbest_param_bagging['model']=t_model_bagging\n",
    "\t\t\t\tbest_param_bagging['n_splits']=n_splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': BaggingClassifier(estimator=SVC(C=10, class_weight='balanced', gamma='auto',\n",
       "                                 probability=True, random_state=21),\n",
       "                   n_estimators=90, random_state=21),\n",
       " 'accuracy': 0.9467455621301775,\n",
       " 'precision': 0.9480653030948889,\n",
       " 'recall': 0.9467455621301775,\n",
       " 'n_splits': 8}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_param_bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Choose the best model in terms of accuracy (if there are several of them with equal values, choose the one with the higher precision).\n",
    "2. Analyze: for which weekday your model makes the most errors (in % of the total number of samples of that class in your full dataset), for which labname and for which users.\n",
    "3. Save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best = best_param_bagging['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df=df.copy()\n",
    "pred_y=model_best.predict(X)\n",
    "t_df['pred']=pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dayofweek\n",
       "6    0.013049\n",
       "5    0.009490\n",
       "1    0.009490\n",
       "3    0.008304\n",
       "0    0.004152\n",
       "4    0.001779\n",
       "2    0.001186\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_df[t_df['pred'] != t_df['dayofweek']]['dayofweek'].value_counts() / len(pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User with max error: uid_user_25 | Percent error: 0.41518386714116245%\n"
     ]
    }
   ],
   "source": [
    "error = t_df[t_df['pred'] != t_df['dayofweek']]\n",
    "users_list = [i for i in t_df.columns if i.startswith('uid')]\n",
    "lab_list = [i for i in t_df.columns if i.startswith('labname')]\n",
    "max_error = 0\n",
    "max_user = ''\n",
    "for user in users_list:\n",
    "    error_perc = error[user].sum() / len(pred_y)\n",
    "    if error_perc > max_error:\n",
    "        max_error = error_perc\n",
    "        max_user = user\n",
    "print(f\"User with max error: {max_user} | Percent error: {max_error * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labname with max error: labname_project1 | Percent error: 1.9572953736654803%\n"
     ]
    }
   ],
   "source": [
    "max_error = 0\n",
    "max_lab = ''\n",
    "for lab in lab_list:\n",
    "    error_perc = error[lab].sum() / len(pred_y)\n",
    "    if error_perc > max_error:\n",
    "        max_error = error_perc\n",
    "        max_lab = lab\n",
    "print(f\"Labname with max error: {max_lab} | Percent error: {max_error * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_ex03.joblib']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model_best, 'model_ex03.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
