{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 09. Exercise 00\n",
    "# Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read the file `dayofweek.csv` that you used in the previous day to a dataframe.\n",
    "2. Using `train_test_split` with parameters `test_size=0.2`, `random_state=21` get `X_train`, `y_train`, `X_test`, `y_test`. Use the additional parameter `stratify`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numTrials</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>uid_user_0</th>\n",
       "      <th>uid_user_1</th>\n",
       "      <th>uid_user_10</th>\n",
       "      <th>uid_user_11</th>\n",
       "      <th>uid_user_12</th>\n",
       "      <th>uid_user_13</th>\n",
       "      <th>uid_user_14</th>\n",
       "      <th>...</th>\n",
       "      <th>labname_lab02</th>\n",
       "      <th>labname_lab03</th>\n",
       "      <th>labname_lab03s</th>\n",
       "      <th>labname_lab05s</th>\n",
       "      <th>labname_laba04</th>\n",
       "      <th>labname_laba04s</th>\n",
       "      <th>labname_laba05</th>\n",
       "      <th>labname_laba06</th>\n",
       "      <th>labname_laba06s</th>\n",
       "      <th>labname_project1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.788667</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.756764</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.724861</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.692958</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.661055</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>-0.533442</td>\n",
       "      <td>0.945382</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>-0.629151</td>\n",
       "      <td>0.945382</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>-0.597248</td>\n",
       "      <td>0.945382</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>-0.565345</td>\n",
       "      <td>0.945382</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>-0.533442</td>\n",
       "      <td>0.945382</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1686 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      numTrials      hour  dayofweek  uid_user_0  uid_user_1  uid_user_10  \\\n",
       "0     -0.788667 -2.562352          4         0.0         0.0          0.0   \n",
       "1     -0.756764 -2.562352          4         0.0         0.0          0.0   \n",
       "2     -0.724861 -2.562352          4         0.0         0.0          0.0   \n",
       "3     -0.692958 -2.562352          4         0.0         0.0          0.0   \n",
       "4     -0.661055 -2.562352          4         0.0         0.0          0.0   \n",
       "...         ...       ...        ...         ...         ...          ...   \n",
       "1681  -0.533442  0.945382          3         0.0         0.0          0.0   \n",
       "1682  -0.629151  0.945382          3         0.0         1.0          0.0   \n",
       "1683  -0.597248  0.945382          3         0.0         1.0          0.0   \n",
       "1684  -0.565345  0.945382          3         0.0         1.0          0.0   \n",
       "1685  -0.533442  0.945382          3         0.0         1.0          0.0   \n",
       "\n",
       "      uid_user_11  uid_user_12  uid_user_13  uid_user_14  ...  labname_lab02  \\\n",
       "0             0.0          0.0          0.0          0.0  ...            0.0   \n",
       "1             0.0          0.0          0.0          0.0  ...            0.0   \n",
       "2             0.0          0.0          0.0          0.0  ...            0.0   \n",
       "3             0.0          0.0          0.0          0.0  ...            0.0   \n",
       "4             0.0          0.0          0.0          0.0  ...            0.0   \n",
       "...           ...          ...          ...          ...  ...            ...   \n",
       "1681          0.0          0.0          0.0          0.0  ...            0.0   \n",
       "1682          0.0          0.0          0.0          0.0  ...            0.0   \n",
       "1683          0.0          0.0          0.0          0.0  ...            0.0   \n",
       "1684          0.0          0.0          0.0          0.0  ...            0.0   \n",
       "1685          0.0          0.0          0.0          0.0  ...            0.0   \n",
       "\n",
       "      labname_lab03  labname_lab03s  labname_lab05s  labname_laba04  \\\n",
       "0               0.0             0.0             0.0             0.0   \n",
       "1               0.0             0.0             0.0             0.0   \n",
       "2               0.0             0.0             0.0             0.0   \n",
       "3               0.0             0.0             0.0             0.0   \n",
       "4               0.0             0.0             0.0             0.0   \n",
       "...             ...             ...             ...             ...   \n",
       "1681            0.0             0.0             0.0             0.0   \n",
       "1682            0.0             0.0             0.0             0.0   \n",
       "1683            0.0             0.0             0.0             0.0   \n",
       "1684            0.0             0.0             0.0             0.0   \n",
       "1685            0.0             0.0             0.0             0.0   \n",
       "\n",
       "      labname_laba04s  labname_laba05  labname_laba06  labname_laba06s  \\\n",
       "0                 0.0             0.0             0.0              0.0   \n",
       "1                 0.0             0.0             0.0              0.0   \n",
       "2                 0.0             0.0             0.0              0.0   \n",
       "3                 0.0             0.0             0.0              0.0   \n",
       "4                 0.0             0.0             0.0              0.0   \n",
       "...               ...             ...             ...              ...   \n",
       "1681              0.0             0.0             0.0              1.0   \n",
       "1682              0.0             0.0             0.0              1.0   \n",
       "1683              0.0             0.0             0.0              1.0   \n",
       "1684              0.0             0.0             0.0              1.0   \n",
       "1685              0.0             0.0             0.0              1.0   \n",
       "\n",
       "      labname_project1  \n",
       "0                  1.0  \n",
       "1                  1.0  \n",
       "2                  1.0  \n",
       "3                  1.0  \n",
       "4                  1.0  \n",
       "...                ...  \n",
       "1681               0.0  \n",
       "1682               0.0  \n",
       "1683               0.0  \n",
       "1684               0.0  \n",
       "1685               0.0  \n",
       "\n",
       "[1686 rows x 44 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/dayofweek.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(columns=['dayofweek'])\n",
    "y=df['dayofweek']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=21, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Logreg regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Default regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train a baseline model with the only parameters `random_state=21`, `fit_intercept=False`.\n",
    "2. Use stratified K-fold cross-validation with `10` splits to evaluate the accuracy of the model\n",
    "\n",
    "\n",
    "The result of the code where you trained and evaluated the baseline model should be exactly like this (use `%%time` to get the info about how long it took to run the cell):\n",
    "\n",
    "```\n",
    "train -  0.62902   |   valid -  0.59259\n",
    "train -  0.64633   |   valid -  0.62963\n",
    "train -  0.63479   |   valid -  0.56296\n",
    "train -  0.65622   |   valid -  0.61481\n",
    "train -  0.63397   |   valid -  0.57778\n",
    "train -  0.64056   |   valid -  0.59259\n",
    "train -  0.64138   |   valid -  0.65926\n",
    "train -  0.65952   |   valid -  0.56296\n",
    "train -  0.64333   |   valid -  0.59701\n",
    "train -  0.63674   |   valid -  0.62687\n",
    "Average accuracy on crossval is 0.60165\n",
    "Std is 0.02943\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossval(n_splits, X, y, model):\n",
    "\tkf = KFold(n_splits=n_splits, shuffle=True, random_state=21)\n",
    "\tl_rmse=list()\n",
    "\tfor ind_train,ind_test in kf.split(X):\n",
    "\t\tt_X_train, t_X_test = X.iloc[ind_train], X.iloc[ind_test]\n",
    "\t\tt_y_train, t_y_test = y.iloc[ind_train], y.iloc[ind_test]\n",
    "\t\t\n",
    "\t\tmodel.fit(t_X_train, t_y_train)\n",
    "\t\tt_y_pred_train = model.predict(t_X_train)\n",
    "\t\tt_y_pred_test = model.predict(t_X_test)\n",
    "\n",
    "\t\tt_rmse_train = accuracy_score(t_y_train, t_y_pred_train)\n",
    "\t\tt_rmse_test = accuracy_score(t_y_test, t_y_pred_test)\n",
    "\n",
    "\t\tl_rmse.append(t_rmse_test)\n",
    "\n",
    "\t\tprint(f\"train -  {t_rmse_train}   |   test -  {t_rmse_test}\")\n",
    "\tprint(f\"Average accuracy on crossval is {np.mean(l_rmse)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6331360946745562"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_logreg = LogisticRegression(random_state=21, fit_intercept=False)\n",
    "model_logreg.fit(X_train, y_train)\n",
    "accuracy_score(model_logreg.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  0.6282135794330916   |   test -  0.7396449704142012\n",
      "train -  0.6526038233355307   |   test -  0.6153846153846154\n",
      "train -  0.6539222148978246   |   test -  0.6094674556213018\n",
      "train -  0.6361239288068556   |   test -  0.5443786982248521\n",
      "train -  0.6453526697429136   |   test -  0.6331360946745562\n",
      "train -  0.6453526697429136   |   test -  0.5798816568047337\n",
      "train -  0.6291172595520421   |   test -  0.5714285714285714\n",
      "train -  0.6442687747035574   |   test -  0.6190476190476191\n",
      "train -  0.6363636363636364   |   test -  0.6011904761904762\n",
      "train -  0.6403162055335968   |   test -  0.6130952380952381\n",
      "Average accuracy on crossval is 0.6126655395886165\n",
      "CPU times: user 2.06 s, sys: 6.19 ms, total: 2.07 s\n",
      "Wall time: 209 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crossval(10, X, y, model_logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Optimizing regularization parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the cells below try different values of penalty: `none`, `l1`, `l2` – you can change the values of solver too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logreg_none = LogisticRegression(penalty=None, random_state=21, fit_intercept=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  0.6611733684904416   |   test -  0.7514792899408284\n",
      "train -  0.6638101516150297   |   test -  0.6331360946745562\n",
      "train -  0.6585365853658537   |   test -  0.621301775147929\n",
      "train -  0.6598549769281477   |   test -  0.5739644970414202\n",
      "train -  0.6671061305207646   |   test -  0.6627218934911243\n",
      "train -  0.6690837178642056   |   test -  0.6153846153846154\n",
      "train -  0.658102766798419   |   test -  0.6190476190476191\n",
      "train -  0.6561264822134387   |   test -  0.6369047619047619\n",
      "train -  0.6574440052700923   |   test -  0.6071428571428571\n",
      "train -  0.6745718050065876   |   test -  0.6369047619047619\n",
      "Average accuracy on crossval is 0.6357988165680473\n",
      "CPU times: user 4.96 s, sys: 9.52 ms, total: 4.97 s\n",
      "Wall time: 506 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crossval(10, X, y, model_logreg_none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logreg_l1 = LogisticRegression(penalty='l1', random_state=21, fit_intercept=False, solver='saga')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  0.6242584047462096   |   test -  0.7337278106508875\n",
      "train -  0.6486486486486487   |   test -  0.621301775147929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  0.6493078444297956   |   test -  0.5976331360946746\n",
      "train -  0.6328279499011207   |   test -  0.5325443786982249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  0.6433750823994726   |   test -  0.6272189349112426\n",
      "train -  0.6506262359920897   |   test -  0.5798816568047337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  0.6304347826086957   |   test -  0.5714285714285714\n",
      "train -  0.6436100131752306   |   test -  0.6309523809523809\n",
      "train -  0.6330698287220027   |   test -  0.6011904761904762\n",
      "train -  0.6469038208168643   |   test -  0.6190476190476191\n",
      "Average accuracy on crossval is 0.611492673992674\n",
      "CPU times: user 2.39 s, sys: 2.38 ms, total: 2.39 s\n",
      "Wall time: 1.91 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ilya/Рабочий стол/s21/DS_Bootcamp.Day09.ID_886524-1/venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crossval(10, X, y, model_logreg_l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logreg_l2 = LogisticRegression(penalty='l2', random_state=21, fit_intercept=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  0.6282135794330916   |   test -  0.7396449704142012\n",
      "train -  0.6526038233355307   |   test -  0.6153846153846154\n",
      "train -  0.6539222148978246   |   test -  0.6094674556213018\n",
      "train -  0.6361239288068556   |   test -  0.5443786982248521\n",
      "train -  0.6453526697429136   |   test -  0.6331360946745562\n",
      "train -  0.6453526697429136   |   test -  0.5798816568047337\n",
      "train -  0.6291172595520421   |   test -  0.5714285714285714\n",
      "train -  0.6442687747035574   |   test -  0.6190476190476191\n",
      "train -  0.6363636363636364   |   test -  0.6011904761904762\n",
      "train -  0.6403162055335968   |   test -  0.6130952380952381\n",
      "Average accuracy on crossval is 0.6126655395886165\n",
      "CPU times: user 2.94 s, sys: 7.94 ms, total: 2.95 s\n",
      "Wall time: 325 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crossval(10, X, y, model_logreg_l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SVM regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Default regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train a baseline model with the only parameters `probability=True`, `kernel='linear'`, `random_state=21`.\n",
    "2. Use stratified K-fold cross-validation with `10` splits to evaluate the accuracy of the model.\n",
    "3. The format of the result of the code where you trained and evaluated the baseline model should be similar to what you have got for the logreg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7159763313609467"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svm = SVC(random_state=21, kernel='linear', probability=True)\n",
    "model_svm.fit(X_train, y_train)\n",
    "accuracy_score(model_svm.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  0.6934739617666447   |   test -  0.7692307692307693\n",
      "train -  0.7112722478576137   |   test -  0.6863905325443787\n",
      "train -  0.7013843111404087   |   test -  0.6745562130177515\n",
      "train -  0.6994067237969677   |   test -  0.6094674556213018\n",
      "train -  0.7007251153592617   |   test -  0.6982248520710059\n",
      "train -  0.7066578773895847   |   test -  0.727810650887574\n",
      "train -  0.7002635046113307   |   test -  0.6547619047619048\n",
      "train -  0.7114624505928854   |   test -  0.6369047619047619\n",
      "train -  0.6956521739130435   |   test -  0.6845238095238095\n",
      "train -  0.7108036890645586   |   test -  0.6428571428571429\n",
      "Average accuracy on crossval is 0.67847280924204\n",
      "CPU times: user 2.88 s, sys: 5.06 ms, total: 2.88 s\n",
      "Wall time: 2.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crossval(10, X, y, model_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Optimizing regularization parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the cells below try different values of the parameter `C`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svm_c1 = SVC(random_state=21, kernel='linear', probability=True, C=1)\n",
    "\n",
    "model_svm_c10 = SVC(random_state=21, kernel='linear', probability=True, C=10)\n",
    "\n",
    "model_svm_c01 = SVC(random_state=21, kernel='linear', probability=True, C=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  0.6934739617666447   |   test -  0.7692307692307693\n",
      "train -  0.7112722478576137   |   test -  0.6863905325443787\n",
      "train -  0.7013843111404087   |   test -  0.6745562130177515\n",
      "train -  0.6994067237969677   |   test -  0.6094674556213018\n",
      "train -  0.7007251153592617   |   test -  0.6982248520710059\n",
      "train -  0.7066578773895847   |   test -  0.727810650887574\n",
      "train -  0.7002635046113307   |   test -  0.6547619047619048\n",
      "train -  0.7114624505928854   |   test -  0.6369047619047619\n",
      "train -  0.6956521739130435   |   test -  0.6845238095238095\n",
      "train -  0.7108036890645586   |   test -  0.6428571428571429\n",
      "Average accuracy on crossval is 0.67847280924204\n",
      "CPU times: user 2.88 s, sys: 2.07 ms, total: 2.88 s\n",
      "Wall time: 2.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crossval(10, X, y, model_svm_c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  0.7646671061305208   |   test -  0.8047337278106509\n",
      "train -  0.7778510217534608   |   test -  0.7218934911242604\n",
      "train -  0.7771918259723137   |   test -  0.7692307692307693\n",
      "train -  0.7798286090969018   |   test -  0.7041420118343196\n",
      "train -  0.7640079103493738   |   test -  0.8165680473372781\n",
      "train -  0.7679630850362558   |   test -  0.7692307692307693\n",
      "train -  0.7687747035573123   |   test -  0.7083333333333334\n",
      "train -  0.7760210803689065   |   test -  0.6964285714285714\n",
      "train -  0.7786561264822134   |   test -  0.75\n",
      "train -  0.7779973649538867   |   test -  0.7023809523809523\n",
      "Average accuracy on crossval is 0.7442941673710906\n",
      "CPU times: user 4.41 s, sys: 120 μs, total: 4.41 s\n",
      "Wall time: 4.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crossval(10, X, y, model_svm_c10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  0.5886618325642716   |   test -  0.6804733727810651\n",
      "train -  0.5781147000659196   |   test -  0.591715976331361\n",
      "train -  0.5866842452208306   |   test -  0.5621301775147929\n",
      "train -  0.5899802241265656   |   test -  0.47337278106508873\n",
      "train -  0.5728411338167436   |   test -  0.5443786982248521\n",
      "train -  0.5675675675675675   |   test -  0.5680473372781065\n",
      "train -  0.6001317523056654   |   test -  0.5178571428571429\n",
      "train -  0.6001317523056654   |   test -  0.5714285714285714\n",
      "train -  0.5718050065876152   |   test -  0.5654761904761905\n",
      "train -  0.5856389986824769   |   test -  0.5535714285714286\n",
      "Average accuracy on crossval is 0.56284516765286\n",
      "CPU times: user 3.05 s, sys: 2.05 ms, total: 3.05 s\n",
      "Wall time: 3.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crossval(10, X, y, model_svm_c01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Default regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train a baseline model with the only parameter `max_depth=10` and `random_state=21`.\n",
    "2. Use stratified K-fold cross-validation with `10` splits to evaluate the accuracy of the model.\n",
    "3. The format of the result of the code where you trained and evaluated the baseline model should be similar to what you have got for the logreg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7396449704142012"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tree = DecisionTreeClassifier(max_depth=10, random_state=21)\n",
    "model_tree.fit(X_train, y_train)\n",
    "accuracy_score(model_tree.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  0.8088332234673699   |   test -  0.7810650887573964\n",
      "train -  0.8220171390903098   |   test -  0.7633136094674556\n",
      "train -  0.8180619644034278   |   test -  0.7396449704142012\n",
      "train -  0.8233355306526038   |   test -  0.757396449704142\n",
      "train -  0.8134475939353988   |   test -  0.7869822485207101\n",
      "train -  0.8213579433091628   |   test -  0.8165680473372781\n",
      "train -  0.8142292490118577   |   test -  0.7321428571428571\n",
      "train -  0.8194993412384717   |   test -  0.7202380952380952\n",
      "train -  0.8241106719367589   |   test -  0.7619047619047619\n",
      "train -  0.8254281949934124   |   test -  0.7559523809523809\n",
      "Average accuracy on crossval is 0.761520850943928\n",
      "CPU times: user 53.7 ms, sys: 996 μs, total: 54.7 ms\n",
      "Wall time: 54.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crossval(10, X, y, model_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Optimizing regularization parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the cells below try different values of the parameter `max_depth`.\n",
    "2. As a bonus, play with other regularization parameters trying to find the best combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tree_depth5 = DecisionTreeClassifier(max_depth=5, random_state=21)\n",
    "\n",
    "model_tree_depth15 = DecisionTreeClassifier(max_depth=15, random_state=21)\n",
    "\n",
    "model_tree_depth20 = DecisionTreeClassifier(max_depth=20, random_state=21)\n",
    "\n",
    "model_tree_depth25 = DecisionTreeClassifier(max_depth=25, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  0.6051417270929466   |   test -  0.6804733727810651\n",
      "train -  0.6104152933421226   |   test -  0.6272189349112426\n",
      "train -  0.6301911667765326   |   test -  0.5976331360946746\n",
      "train -  0.6163480553724456   |   test -  0.5266272189349113\n",
      "train -  0.6176664469347396   |   test -  0.5621301775147929\n",
      "train -  0.6077785102175346   |   test -  0.6331360946745562\n",
      "train -  0.616600790513834   |   test -  0.5416666666666666\n",
      "train -  0.6258234519104084   |   test -  0.6130952380952381\n",
      "train -  0.6284584980237155   |   test -  0.5892857142857143\n",
      "train -  0.61133069828722   |   test -  0.5952380952380952\n",
      "Average accuracy on crossval is 0.5966504649196956\n",
      "CPU times: user 47.2 ms, sys: 13 μs, total: 47.2 ms\n",
      "Wall time: 46.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crossval(10, X, y, model_tree_depth5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  0.9419907712590639   |   test -  0.8875739644970414\n",
      "train -  0.946605141727093   |   test -  0.8816568047337278\n",
      "train -  0.954515491100857   |   test -  0.863905325443787\n",
      "train -  0.9571522742254449   |   test -  0.8579881656804734\n",
      "train -  0.952537903757416   |   test -  0.863905325443787\n",
      "train -  0.956493078444298   |   test -  0.9171597633136095\n",
      "train -  0.9472990777338604   |   test -  0.8333333333333334\n",
      "train -  0.9552042160737813   |   test -  0.8511904761904762\n",
      "train -  0.9466403162055336   |   test -  0.8392857142857143\n",
      "train -  0.9472990777338604   |   test -  0.8333333333333334\n",
      "Average accuracy on crossval is 0.8629332206255282\n",
      "CPU times: user 60.2 ms, sys: 1.99 ms, total: 62.2 ms\n",
      "Wall time: 61.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crossval(10, X, y, model_tree_depth15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  0.99340804218853   |   test -  0.893491124260355\n",
      "train -  0.98681608437706   |   test -  0.8994082840236687\n",
      "train -  0.990112063282795   |   test -  0.893491124260355\n",
      "train -  0.984179301252472   |   test -  0.8875739644970414\n",
      "train -  0.992089650626236   |   test -  0.9053254437869822\n",
      "train -  0.986156888595913   |   test -  0.9230769230769231\n",
      "train -  0.9901185770750988   |   test -  0.875\n",
      "train -  0.9920948616600791   |   test -  0.8869047619047619\n",
      "train -  0.9888010540184453   |   test -  0.8511904761904762\n",
      "train -  0.9855072463768116   |   test -  0.8630952380952381\n",
      "Average accuracy on crossval is 0.8878557340095803\n",
      "CPU times: user 60.6 ms, sys: 1.99 ms, total: 62.6 ms\n",
      "Wall time: 61 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crossval(10, X, y, model_tree_depth20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  0.999340804218853   |   test -  0.8875739644970414\n",
      "train -  0.998681608437706   |   test -  0.9053254437869822\n",
      "train -  0.999340804218853   |   test -  0.8875739644970414\n",
      "train -  0.998681608437706   |   test -  0.9053254437869822\n",
      "train -  0.999340804218853   |   test -  0.9053254437869822\n",
      "train -  0.997363216875412   |   test -  0.9467455621301775\n",
      "train -  1.0   |   test -  0.8928571428571429\n",
      "train -  1.0   |   test -  0.8928571428571429\n",
      "train -  0.997364953886693   |   test -  0.8630952380952381\n",
      "train -  0.9993412384716732   |   test -  0.8869047619047619\n",
      "Average accuracy on crossval is 0.8973584108199493\n",
      "CPU times: user 60.9 ms, sys: 1.99 ms, total: 62.9 ms\n",
      "Wall time: 61.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crossval(10, X, y, model_tree_depth25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Default regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train a baseline model with the only parameters `n_estimators=50`, `max_depth=14`, `random_state=21`.\n",
    "2. Use stratified K-fold cross-validation with `10` splits to evaluate the accuracy of the model.\n",
    "3. The format of the result of the code where you trained and evaluated the baseline model should be similar to what you have got for the logreg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.908284023668639"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_forest = RandomForestClassifier(n_estimators=50, max_depth=14, random_state=21)\n",
    "model_forest.fit(X_train, y_train)\n",
    "accuracy_score(model_forest.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  0.967699406723797   |   test -  0.9230769230769231\n",
      "train -  0.96044825313118   |   test -  0.9230769230769231\n",
      "train -  0.958470665787739   |   test -  0.8698224852071006\n",
      "train -  0.966381015161503   |   test -  0.8520710059171598\n",
      "train -  0.97363216875412   |   test -  0.9230769230769231\n",
      "train -  0.9630850362557679   |   test -  0.9467455621301775\n",
      "train -  0.955862977602108   |   test -  0.8869047619047619\n",
      "train -  0.9683794466403162   |   test -  0.8630952380952381\n",
      "train -  0.9703557312252964   |   test -  0.9047619047619048\n",
      "train -  0.9703557312252964   |   test -  0.8809523809523809\n",
      "Average accuracy on crossval is 0.8973584108199493\n",
      "CPU times: user 687 ms, sys: 19 ms, total: 706 ms\n",
      "Wall time: 703 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crossval(10, X, y, model_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Optimizing regularization parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the new cells try different values of the parameters `max_depth` and `n_estimators`.\n",
    "2. As a bonus, play with other regularization parameters trying to find the best combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_forest_n25_d14 = RandomForestClassifier(n_estimators=25, max_depth=14, random_state=21)\n",
    "\n",
    "model_forest_n75_d14 = RandomForestClassifier(n_estimators=75, max_depth=14, random_state=21)\n",
    "\n",
    "model_forest_n50_d5 = RandomForestClassifier(n_estimators=10, max_depth=5, random_state=21)\n",
    "\n",
    "model_forest_n50_d20 = RandomForestClassifier(n_estimators=10, max_depth=20, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  0.967699406723797   |   test -  0.9171597633136095\n",
      "train -  0.9512195121951219   |   test -  0.9171597633136095\n",
      "train -  0.951878707976269   |   test -  0.8698224852071006\n",
      "train -  0.955833882663151   |   test -  0.8165680473372781\n",
      "train -  0.9611074489123269   |   test -  0.9171597633136095\n",
      "train -  0.956493078444298   |   test -  0.9349112426035503\n",
      "train -  0.9525691699604744   |   test -  0.8809523809523809\n",
      "train -  0.9598155467720685   |   test -  0.8511904761904762\n",
      "train -  0.9552042160737813   |   test -  0.875\n",
      "train -  0.9677206851119895   |   test -  0.8511904761904762\n",
      "Average accuracy on crossval is 0.8831114398422091\n",
      "CPU times: user 386 ms, sys: 5 ms, total: 391 ms\n",
      "Wall time: 390 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crossval(10, X, y, model_forest_n25_d14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  0.9670402109426499   |   test -  0.9230769230769231\n",
      "train -  0.963744232036915   |   test -  0.9408284023668639\n",
      "train -  0.9650626235992089   |   test -  0.8698224852071006\n",
      "train -  0.968358602504944   |   test -  0.8520710059171598\n",
      "train -  0.975609756097561   |   test -  0.9230769230769231\n",
      "train -  0.965721819380356   |   test -  0.9408284023668639\n",
      "train -  0.9644268774703557   |   test -  0.875\n",
      "train -  0.969038208168643   |   test -  0.8630952380952381\n",
      "train -  0.9756258234519104   |   test -  0.8988095238095238\n",
      "train -  0.9703557312252964   |   test -  0.8809523809523809\n",
      "Average accuracy on crossval is 0.8967561284868978\n",
      "CPU times: user 1.04 s, sys: 18 ms, total: 1.05 s\n",
      "Wall time: 1.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crossval(10, X, y, model_forest_n75_d14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  0.6084377059986816   |   test -  0.7218934911242604\n",
      "train -  0.5754779169413315   |   test -  0.5857988165680473\n",
      "train -  0.6328279499011207   |   test -  0.5976331360946746\n",
      "train -  0.6064601186552406   |   test -  0.5088757396449705\n",
      "train -  0.6044825313117996   |   test -  0.5621301775147929\n",
      "train -  0.6090969017798286   |   test -  0.591715976331361\n",
      "train -  0.6073781291172595   |   test -  0.5654761904761905\n",
      "train -  0.6119894598155468   |   test -  0.625\n",
      "train -  0.6106719367588933   |   test -  0.6071428571428571\n",
      "train -  0.6054018445322793   |   test -  0.5595238095238095\n",
      "Average accuracy on crossval is 0.5925190194420963\n",
      "CPU times: user 145 ms, sys: 2 ms, total: 147 ms\n",
      "Wall time: 146 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crossval(10, X, y, model_forest_n50_d5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  0.990771259063942   |   test -  0.9112426035502958\n",
      "train -  0.988793671720501   |   test -  0.9408284023668639\n",
      "train -  0.987475280158207   |   test -  0.893491124260355\n",
      "train -  0.988793671720501   |   test -  0.8698224852071006\n",
      "train -  0.990112063282795   |   test -  0.9230769230769231\n",
      "train -  0.987475280158207   |   test -  0.9349112426035503\n",
      "train -  0.9888010540184453   |   test -  0.8928571428571429\n",
      "train -  0.9894598155467721   |   test -  0.8809523809523809\n",
      "train -  0.9907773386034255   |   test -  0.9047619047619048\n",
      "train -  0.9907773386034255   |   test -  0.8928571428571429\n",
      "Average accuracy on crossval is 0.9044801352493661\n",
      "CPU times: user 190 ms, sys: 5 ms, total: 195 ms\n",
      "Wall time: 193 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crossval(10, X, y, model_forest_n50_d20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Choose the best model and use it to make predictions for the test dataset.\n",
    "2. Calculate the final accuracy.\n",
    "3. Analyze: for which weekday your model makes the most errors (in % of the total number of samples of that class in your test dataset).\n",
    "4. Save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best = model_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = model_best.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.961447212336892"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(pred_y, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 4, ..., 3, 3, 3], shape=(1686,))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>ans_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1686 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dayofweek  ans_model\n",
       "0             4          4\n",
       "1             4          4\n",
       "2             4          4\n",
       "3             4          4\n",
       "4             4          4\n",
       "...         ...        ...\n",
       "1681          3          3\n",
       "1682          3          3\n",
       "1683          3          3\n",
       "1684          3          3\n",
       "1685          3          3\n",
       "\n",
       "[1686 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = pd.DataFrame(y).reset_index().drop(columns=['index'])\n",
    "temp_df['ans_model'] = pred_y\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dayofweek\n",
       "2    0.007711\n",
       "5    0.007117\n",
       "1    0.006524\n",
       "6    0.005931\n",
       "0    0.005338\n",
       "3    0.002966\n",
       "4    0.002966\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df[temp_df['dayofweek'] != temp_df['ans_model']].dayofweek.value_counts() / len(pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_ex00.joblib']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model_best, 'model_ex00.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
